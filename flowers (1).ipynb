{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FAj6ZTwy4IO",
        "outputId": "2fe6d06f-ea73-4e67-cc73-ea3199747552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4308\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import cv2 \n",
        "import pickle as pickle \n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/flow'\n",
        "\n",
        "categories = ['daisy', 'dandelion' , 'rose', 'sunflower', 'tulip']\n",
        "\n",
        "data = []\n",
        "\n",
        "def make_data():\n",
        "    for category in categories:\n",
        "        path = os.path.join(data_dir, category)\n",
        "        label = categories.index(category)\n",
        "\n",
        "        for img_name in os.listdir(path):\n",
        "            image_path = os.path.join(path, img_name)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "\n",
        "            try:\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                image = cv2.resize(image, (224,224))\n",
        "                image = np.array(image)\n",
        "\n",
        "                data.append([image, label])\n",
        "\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "    print(len(data))\n",
        "    pik = open('flower.pickle','wb')\n",
        "    pickle.dump(data, pik)\n",
        "    pik.close()\n",
        "make_data()\n",
        "def load_data():\n",
        "    pick  = open('flower.pickle', 'rb')\n",
        "    data = pickle.load(pick)\n",
        "\n",
        "    pick.close()\n",
        "\n",
        "#np.random(data)\n",
        "\n",
        "    feature = []\n",
        "    labels = []\n",
        "\n",
        "    for img, label in data:\n",
        "        feature.append(img)\n",
        "        labels.append(label)\n",
        "\n",
        "    feature = np.array(feature, dtype = np.float32)\n",
        "    feature = feature/ 255.\n",
        "\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return [feature, labels]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AWxnkljGy9zT"
      },
      "outputs": [],
      "source": [
        "feature,label = load_data()\n",
        "categories = ['daisy', 'dandelion' , 'rose', 'sunflower', 'tulip']\n",
        "x_train, x_test, y_train, y_test = train_test_split(feature,label,test_size=0.1,shuffle=True)\n",
        "train_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train)) \n",
        "x_train, x_test = tf.cast(x_train, tf.float32), tf.cast(x_test, tf.float32)\n",
        "train_dataset=train_dataset.batch(batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PvJxACaly9vs"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nmCtvNSdy9l9"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding='same',input_shape=[224, 224, 3]))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2,padding='same'))\n",
        "\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2,padding='same'))\n",
        "\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2,padding='same'))\n",
        "\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2,padding='same'))\n",
        "\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2,padding='same'))\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0SRi8zVtzbID"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W3UJ0FhIkvm",
        "outputId": "f4dcf9f1-1700-4c69-a75c-e23375c182f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(lr=0.0001)\n",
        "cnn.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcDc4iQ8Ikat"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnWnjgWSy9Vw",
        "outputId": "24007c61-27b1-476f-a81d-81f1d08a0443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  8/122 [>.............................] - ETA: 1:51:10 - loss: 1.6127 - accuracy: 0.2305"
          ]
        }
      ],
      "source": [
        "cnn.fit(x_train,y_train, validation_data = (x_test, y_test), epochs = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoGgaFizhCBD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTU_v_J-VVDL"
      },
      "outputs": [],
      "source": [
        "prediction = cnn(x_test[0:9])\n",
        "plt.figure(figsize=(14,14))\n",
        "\n",
        "for i in range(9):\n",
        "   plt.subplot(3,3,i+1)\n",
        "   plt.imshow(x_test[i])\n",
        "   plt.xlabel('Predicted:%s\\n Actual: %s'%(categories[np.argmax(prediction[i])],\n",
        "              categories[y_test[i]]))\n",
        "   \n",
        "   plt.xticks([])\n",
        "plt.show()   \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "img = image.load_img('/content/drive/MyDrive/flow/daisy/10437754174_22ec990b77_m.jpg', target_size=(224,224,3))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "evbpqpGdIQxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)"
      ],
      "metadata": {
        "id": "PdMA7ywuJ7vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions =cnn.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(categories[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "id": "C8OG72JGPHln"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "flowers.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}